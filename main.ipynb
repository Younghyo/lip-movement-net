{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40534f4-f3e7-4e56-af5c-79ac44dfd1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): - "
     ]
    }
   ],
   "source": [
    "!conda install tensorflow-gpu==1.8 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fece166d-77d8-4e79-bf04-c69eb6954462",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded plugins: dkms-build-requires, extras_suggestions, langpacks, priorities,\n",
      "              : update-motd, versionlock\n",
      "amzn2-core                                               | 3.7 kB     00:00     \n",
      "amzn2extra-docker                                        | 3.0 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "libnvidia-container/x86_64/signature                     |  833 B     00:00     \n",
      "libnvidia-container/x86_64/signature                     | 2.1 kB     00:00 !!! \n",
      "neuron                                                   | 2.9 kB     00:00     \n",
      "nvidia-container-runtime/x86_64/signature                |  833 B     00:00     \n",
      "nvidia-container-runtime/x86_64/signature                | 2.1 kB     00:00 !!! \n",
      "nvidia-docker/x86_64/signature                           |  833 B     00:00     \n",
      "nvidia-docker/x86_64/signature                           | 2.1 kB     00:00 !!! \n",
      "61 packages excluded due to repository priority protections\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package libpng-devel.x86_64 2:1.5.13-8.amzn2 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package            Arch         Version                 Repository        Size\n",
      "================================================================================\n",
      "Installing:\n",
      " libpng-devel       x86_64       2:1.5.13-8.amzn2        amzn2-core       122 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package\n",
      "\n",
      "Total download size: 122 k\n",
      "Installed size: 211 k\n",
      "Downloading packages:\n",
      "libpng-devel-1.5.13-8.amzn2.x86_64.rpm                     | 122 kB   00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "Warning: RPMDB altered outside of yum.\n",
      "  Installing : 2:libpng-devel-1.5.13-8.amzn2.x86_64                         1/1 \n",
      "  Verifying  : 2:libpng-devel-1.5.13-8.amzn2.x86_64                         1/1 \n",
      "\n",
      "Installed:\n",
      "  libpng-devel.x86_64 2:1.5.13-8.amzn2                                          \n",
      "\n",
      "Complete!\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting dlib\n",
      "  Downloading dlib-19.24.0.tar.gz (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.24.0-cp310-cp310-linux_x86_64.whl size=4021274 sha256=2d5274808b2a2da5ad41bf394e1c1662a07e0b3f84fac7d274a80af9ed310a02\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/49/f6/12/8db371b40ce7b30c2b5a41f96f73bf7d0712db16bb0c1ef13f\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.24.0\n"
     ]
    }
   ],
   "source": [
    "!sudo yum install libpng-devel -y\n",
    "!pip install dlib\n",
    "!pip install tensorflow\n",
    "!pip install progressbar\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea452b2-3372-45c5-9182-c4b90a279cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/python3.7/site-packages (from scikit-learn) (1.21.6)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e17476c-6a5d-48f7-8364-359d658aacf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.15\n",
      "Name: tensorflow\n",
      "Version: 1.8.0\n",
      "Summary: TensorFlow helps the tensors flow\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: opensource@google.com\n",
      "License: Apache 2.0\n",
      "Location: /home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages\n",
      "Requires: wheel, numpy, six, absl-py, tensorboard, gast, protobuf, termcolor, grpcio, astor\n",
      "Required-by: \n",
      "Name: Keras\n",
      "Version: 2.2.0\n",
      "Summary: Deep Learning for humans\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Francois Chollet\n",
      "Author-email: francois.chollet@gmail.com\n",
      "License: MIT\n",
      "Location: /home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages\n",
      "Requires: numpy, keras-preprocessing, pyyaml, keras-applications, h5py, scipy, six\n",
      "Required-by: Keras-Preprocessing, Keras-Applications\n",
      "Name: h5py\n",
      "Version: 2.10.0\n",
      "Summary: Read and write HDF5 files from Python\n",
      "Home-page: http://www.h5py.org\n",
      "Author: Andrew Collette\n",
      "Author-email: andrew.collette@gmail.com\n",
      "License: BSD\n",
      "Location: /home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages\n",
      "Requires: six, numpy\n",
      "Required-by: Keras, Keras-Applications\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!pip show tensorflow\n",
    "!pip show keras\n",
    "!pip show h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565315dd-f359-46ac-b71c-a840feb61a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/py_36_3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from src.lip_movement_net import test_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86949bd9-69f9-4511-ab7d-fe5c5bc7a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.9489208  0.05107918]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.95155865 0.04844135]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.94441634 0.05558367]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.96102935 0.03897071]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.96531326 0.03468676]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.9653216  0.03467846]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.9892916  0.01070841]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.9787467 0.0212533]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.96855205 0.03144789]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.92708194 0.07291804]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.96159744 0.03840258]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.98079866 0.0192014 ]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.96913356 0.03086641]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.9654677  0.03453236]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.98130095 0.01869904]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.991919   0.00808103]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.99152315 0.00847685]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.98975754 0.01024239]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n",
      "Returning (1, 136)\n",
      "y_pred=[[0.9883426  0.01165741]] y_pred_max=0\n",
      "Fetching face detections and landmarks...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a86ef6cdc2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"videos/044598381-carl-rowan-delivering-speech-a.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/1_32_False_True_0.25_lip_motion_net_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/lip_movement_net/src/lip_movement_net.py\u001b[0m in \u001b[0;36mtest_video\u001b[0;34m(video_path, shape_predictor_file, model)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial_points_vector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_facial_landmark_vectors_from_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfacial_points_vector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/lip_movement_net/src/lip_movement_net.py\u001b[0m in \u001b[0;36mget_facial_landmark_vectors_from_frame\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0mfacial_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_video(\"videos/044598381-carl-rowan-delivering-speech-a.mp4\", \"models/shape_predictor_68_face_landmarks.dat\", \"models/1_32_False_True_0.25_lip_motion_net_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
